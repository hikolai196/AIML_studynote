{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM+dTg3aZnKN6nSTla/Z0nH"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"fe8ed05951f84f2792f26b2580c649e8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0ec29d7c95ad4d6f8b1e662325f4c86e","IPY_MODEL_9ff0664d5bf64970b1fa8b0ee7a96a71","IPY_MODEL_e954ea5d3d904d10a45dac4a3c8d3135"],"layout":"IPY_MODEL_baf1c34863a94e5cafba3cc3dbff8fe6"}},"0ec29d7c95ad4d6f8b1e662325f4c86e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ff1378e9516343e6853b4ed793aabf75","placeholder":"​","style":"IPY_MODEL_1c2c65b8b0724419b287bd6e0d3bee63","value":"config.json: 100%"}},"9ff0664d5bf64970b1fa8b0ee7a96a71":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_028d97a3e2434087a8e444def6356e90","max":629,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7d3b1582f0dc46c1a76c71694389d837","value":629}},"e954ea5d3d904d10a45dac4a3c8d3135":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e3a961fa6d8f4a41b76817f5a4187003","placeholder":"​","style":"IPY_MODEL_22e5df57ae1042a9808450afe895bb12","value":" 629/629 [00:00&lt;00:00, 8.25kB/s]"}},"baf1c34863a94e5cafba3cc3dbff8fe6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ff1378e9516343e6853b4ed793aabf75":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1c2c65b8b0724419b287bd6e0d3bee63":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"028d97a3e2434087a8e444def6356e90":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7d3b1582f0dc46c1a76c71694389d837":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e3a961fa6d8f4a41b76817f5a4187003":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"22e5df57ae1042a9808450afe895bb12":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"93d0fa07573d4f20829ce4e085b804ae":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d08c3587f1824e949ee6f95ec2164513","IPY_MODEL_18c6798927764af28b7a4b29ad0e5f16","IPY_MODEL_f9f49aa54a8c49248d5d0f797a05c468"],"layout":"IPY_MODEL_fbff010f602a42748a05b1b1d60c8fb3"}},"d08c3587f1824e949ee6f95ec2164513":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_57ae61048689429387628ad12ded1031","placeholder":"​","style":"IPY_MODEL_5066b3babcf54950ac8f6384f2ac4713","value":"model.safetensors: 100%"}},"18c6798927764af28b7a4b29ad0e5f16":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_27cbf2d2e0f648698a6dfaa621c97a53","max":267832558,"min":0,"orientation":"horizontal","style":"IPY_MODEL_eac1f5994ccd440891e6dc2c2c2fc30c","value":267832558}},"f9f49aa54a8c49248d5d0f797a05c468":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9470da078c1848d294bb6eab9f741147","placeholder":"​","style":"IPY_MODEL_09242597b0974c63954fcdc76d8d6fa1","value":" 268M/268M [00:02&lt;00:00, 171MB/s]"}},"fbff010f602a42748a05b1b1d60c8fb3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"57ae61048689429387628ad12ded1031":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5066b3babcf54950ac8f6384f2ac4713":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"27cbf2d2e0f648698a6dfaa621c97a53":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eac1f5994ccd440891e6dc2c2c2fc30c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9470da078c1848d294bb6eab9f741147":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"09242597b0974c63954fcdc76d8d6fa1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"12cee0d391bf410ca6a1766e7a17ed3f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1346a66c59a24866a44fd8129467042d","IPY_MODEL_67b11d23a61a42099b72f1074d8c461a","IPY_MODEL_c91378932c6b4a9283cdeeeed90e12e6"],"layout":"IPY_MODEL_4082d59c5cd34075bb760939ea8d5361"}},"1346a66c59a24866a44fd8129467042d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7e36eb67f9f54ee8b9fde5f7b780b5b7","placeholder":"​","style":"IPY_MODEL_e284f00702fb4ab3b574c29a57c13591","value":"tokenizer_config.json: 100%"}},"67b11d23a61a42099b72f1074d8c461a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7691f35c1d4944d28a56c8f338de9103","max":48,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c89bcba1de764d11a487070ebc06549f","value":48}},"c91378932c6b4a9283cdeeeed90e12e6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_522585be5d7d4e07b306cb6b0a787182","placeholder":"​","style":"IPY_MODEL_7262e28d92d64a35830a5da4a30b9c50","value":" 48.0/48.0 [00:00&lt;00:00, 1.34kB/s]"}},"4082d59c5cd34075bb760939ea8d5361":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7e36eb67f9f54ee8b9fde5f7b780b5b7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e284f00702fb4ab3b574c29a57c13591":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7691f35c1d4944d28a56c8f338de9103":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c89bcba1de764d11a487070ebc06549f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"522585be5d7d4e07b306cb6b0a787182":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7262e28d92d64a35830a5da4a30b9c50":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cf14fbdf087747c2b6f407360db8389e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_99d9e8c59aa649ff8eb4c2afcf43fd95","IPY_MODEL_d999409942c74faf8ce99537b8f5e8ed","IPY_MODEL_1efe04c7ecde4a8faaf113f7aaac39fb"],"layout":"IPY_MODEL_19dfef1e35ce4243b5932ae5102c91d3"}},"99d9e8c59aa649ff8eb4c2afcf43fd95":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d5f031fecc294319a90ee8db6243d7e7","placeholder":"​","style":"IPY_MODEL_5d47b721eee14fccada11e98438171df","value":"vocab.txt: 100%"}},"d999409942c74faf8ce99537b8f5e8ed":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_048efe644e124dd6b83609c90cc8ecc5","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1c41f870a4ae4ea5a99dc9d40ca56dd8","value":231508}},"1efe04c7ecde4a8faaf113f7aaac39fb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_78a973a118c645eb8d4817b12f7fa4e2","placeholder":"​","style":"IPY_MODEL_49e2a781ea2640ec896c64ecb5ca8775","value":" 232k/232k [00:00&lt;00:00, 1.08MB/s]"}},"19dfef1e35ce4243b5932ae5102c91d3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d5f031fecc294319a90ee8db6243d7e7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5d47b721eee14fccada11e98438171df":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"048efe644e124dd6b83609c90cc8ecc5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1c41f870a4ae4ea5a99dc9d40ca56dd8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"78a973a118c645eb8d4817b12f7fa4e2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"49e2a781ea2640ec896c64ecb5ca8775":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["# Natural Language Processing (NLP)\n","A field that involves the interaction between computers and human language. It encompasses a variety of tasks such as text classification, sentiment analysis, machine translation, and more. Here are some fundamental concepts and we'll then move on to practical examples."],"metadata":{"id":"Jxf-ubAqK83p"}},{"cell_type":"markdown","source":["## Fundamental Concepts\n"],"metadata":{"id":"JECW5kJFLeIF"}},{"cell_type":"markdown","source":["### Tokenization:\n","Splitting text into individual words or tokens."],"metadata":{"id":"Y8AAXdAsL44Z"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lyUSQRxsK8Ch","executionInfo":{"status":"ok","timestamp":1721983078424,"user_tz":-480,"elapsed":5613,"user":{"displayName":"Yen-Ting “Hiko” Lai","userId":"06414485255104484077"}},"outputId":"75820a92-b873-437c-d891-aa2b4cc35ee5"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"output_type":"stream","name":"stdout","text":["['Natural', 'Language', 'Processing', 'is', 'fascinating', '!']\n"]}],"source":["import nltk\n","nltk.download('punkt')\n","from nltk.tokenize import word_tokenize\n","\n","text = \"Natural Language Processing is fascinating!\"\n","tokens = word_tokenize(text)\n","print(tokens)"]},{"cell_type":"markdown","source":["### Stemming and Lemmatization:\n","Reducing words to their base or root form."],"metadata":{"id":"251o2PmKL-N6"}},{"cell_type":"code","source":["from nltk.stem import PorterStemmer\n","from nltk.stem import WordNetLemmatizer\n","nltk.download('wordnet')\n","\n","stemmer = PorterStemmer()\n","lemmatizer = WordNetLemmatizer()\n","\n","word = \"running\"\n","print(\"Stemmed:\", stemmer.stem(word))\n","print(\"Lemmatized:\", lemmatizer.lemmatize(word, pos='v'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r6pTKu38MUcR","executionInfo":{"status":"ok","timestamp":1721983143070,"user_tz":-480,"elapsed":2680,"user":{"displayName":"Yen-Ting “Hiko” Lai","userId":"06414485255104484077"}},"outputId":"e496220a-35af-4086-98a8-7e272f9c4034"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n"]},{"output_type":"stream","name":"stdout","text":["Stemmed: run\n","Lemmatized: run\n"]}]},{"cell_type":"markdown","source":["### Remove Stop Words:\n","Common words (like \"and\", \"the\", \"is\") that are often removed from text to focus on more meaningful words."],"metadata":{"id":"B06bFs-ZMU4p"}},{"cell_type":"code","source":["from nltk.corpus import stopwords\n","nltk.download('stopwords')\n","\n","stop_words = set(stopwords.words('english'))\n","filtered_tokens = [word for word in tokens if word.lower() not in stop_words]\n","print(filtered_tokens)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yQ1b9-kuMpdn","executionInfo":{"status":"ok","timestamp":1721983225508,"user_tz":-480,"elapsed":340,"user":{"displayName":"Yen-Ting “Hiko” Lai","userId":"06414485255104484077"}},"outputId":"5f43ddfe-f36a-4a48-bfc6-a097b8ac06e6"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["['Natural', 'Language', 'Processing', 'fascinating', '!']\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]}]},{"cell_type":"markdown","source":["### Bag of Words (BoW):\n","Representing text as a set of word counts."],"metadata":{"id":"lscGhCp8Mpzp"}},{"cell_type":"code","source":["from sklearn.feature_extraction.text import CountVectorizer\n","\n","corpus = [\n","    \"Natural Language Processing is fascinating.\",\n","    \"Machine learning is a part of AI.\",\n","    \"Deep learning is a subset of machine learning.\"\n","]\n","\n","vectorizer = CountVectorizer()\n","X = vectorizer.fit_transform(corpus)\n","print(vectorizer.get_feature_names_out())\n","print(X.toarray())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QMsgi-4RM2Bj","executionInfo":{"status":"ok","timestamp":1721983276680,"user_tz":-480,"elapsed":362,"user":{"displayName":"Yen-Ting “Hiko” Lai","userId":"06414485255104484077"}},"outputId":"507c4db5-fd4f-49ea-bdb9-b293f2d92aba"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["['ai' 'deep' 'fascinating' 'is' 'language' 'learning' 'machine' 'natural'\n"," 'of' 'part' 'processing' 'subset']\n","[[0 0 1 1 1 0 0 1 0 0 1 0]\n"," [1 0 0 1 0 1 1 0 1 1 0 0]\n"," [0 1 0 1 0 2 1 0 1 0 0 1]]\n"]}]},{"cell_type":"markdown","source":["### TF-IDF (Term Frequency-Inverse Document Frequency):\n","A statistical measure used to evaluate the importance of a word in a document relative to a collection of documents."],"metadata":{"id":"SJpAG7c_M2JH"}},{"cell_type":"code","source":["from sklearn.feature_extraction.text import TfidfVectorizer\n","\n","vectorizer = TfidfVectorizer()\n","X = vectorizer.fit_transform(corpus)\n","print(vectorizer.get_feature_names_out())\n","print(X.toarray())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ylsGouMsM-Ae","executionInfo":{"status":"ok","timestamp":1721983308574,"user_tz":-480,"elapsed":351,"user":{"displayName":"Yen-Ting “Hiko” Lai","userId":"06414485255104484077"}},"outputId":"ba5b6456-167e-423f-c967-9879f454289c"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["['ai' 'deep' 'fascinating' 'is' 'language' 'learning' 'machine' 'natural'\n"," 'of' 'part' 'processing' 'subset']\n","[[0.         0.         0.47952794 0.28321692 0.47952794 0.\n","  0.         0.47952794 0.         0.         0.47952794 0.        ]\n"," [0.49482971 0.         0.         0.2922544  0.         0.37633075\n","  0.37633075 0.         0.37633075 0.49482971 0.         0.        ]\n"," [0.         0.41454097 0.         0.24483457 0.         0.63053818\n","  0.31526909 0.         0.31526909 0.         0.         0.41454097]]\n"]}]},{"cell_type":"markdown","source":["### Word Embeddings:\n","Representing words in a continuous vector space where semantically similar words are closer together (e.g., Word2Vec, GloVe)."],"metadata":{"id":"eiRC8hyxM-KO"}},{"cell_type":"code","source":["import gensim.downloader as api\n","\n","# Load pre-trained Word2Vec model\n","model = api.load(\"glove-wiki-gigaword-50\")\n","\n","# Get the vector for a word\n","vector = model['king']\n","print(vector)\n","\n","# Find similar words\n","similar_words = model.most_similar('king')\n","print(similar_words)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_UgHFTUhNFgS","executionInfo":{"status":"ok","timestamp":1721983399358,"user_tz":-480,"elapsed":59742,"user":{"displayName":"Yen-Ting “Hiko” Lai","userId":"06414485255104484077"}},"outputId":"e32c96e7-5d12-405d-e63e-15f46ed60b58"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["[==================================================] 100.0% 66.0/66.0MB downloaded\n","[ 0.50451   0.68607  -0.59517  -0.022801  0.60046  -0.13498  -0.08813\n","  0.47377  -0.61798  -0.31012  -0.076666  1.493    -0.034189 -0.98173\n","  0.68229   0.81722  -0.51874  -0.31503  -0.55809   0.66421   0.1961\n"," -0.13495  -0.11476  -0.30344   0.41177  -2.223    -1.0756   -1.0783\n"," -0.34354   0.33505   1.9927   -0.04234  -0.64319   0.71125   0.49159\n","  0.16754   0.34344  -0.25663  -0.8523    0.1661    0.40102   1.1685\n"," -1.0137   -0.21585  -0.15155   0.78321  -0.91241  -1.6106   -0.64426\n"," -0.51042 ]\n","[('prince', 0.8236179351806641), ('queen', 0.7839043140411377), ('ii', 0.7746230363845825), ('emperor', 0.7736247777938843), ('son', 0.766719400882721), ('uncle', 0.7627150416374207), ('kingdom', 0.7542160749435425), ('throne', 0.7539913654327393), ('brother', 0.7492411136627197), ('ruler', 0.7434253692626953)]\n"]}]},{"cell_type":"markdown","source":["### Sequence Models:\n","Models like RNNs, LSTMs, GRUs, and Transformers that handle sequential data."],"metadata":{"id":"00U0LvhoNFoX"}},{"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Embedding, LSTM, Dense\n","\n","# Sample data\n","sentences = [\n","    \"I love machine learning\",\n","    \"Deep learning is amazing\",\n","    \"Natural language processing is a part of AI\",\n","    \"I enjoy learning new things\"\n","]\n","labels = [1, 1, 1, 0]  # 1: positive, 0: negative\n","\n","# Tokenize the sentences\n","tokenizer = Tokenizer(num_words=100)\n","tokenizer.fit_on_texts(sentences)\n","sequences = tokenizer.texts_to_sequences(sentences)\n","\n","# Pad the sequences to ensure they are all the same length\n","max_length = max(len(seq) for seq in sequences)\n","X = pad_sequences(sequences, maxlen=max_length, padding='post')\n","\n","# Convert labels to a numpy array\n","y = np.array(labels)\n","\n","# Define the LSTM model\n","model = Sequential()\n","model.add(Embedding(input_dim=100, output_dim=16, input_length=max_length))\n","model.add(LSTM(32))\n","model.add(Dense(1, activation='sigmoid'))\n","\n","# Compile the model\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","\n","# Train the model\n","model.fit(X, y, epochs=10, verbose=1)\n","\n","# Evaluate the model\n","loss, accuracy = model.evaluate(X, y, verbose=0)\n","print(f'Test Accuracy: {accuracy:.4f}')\n","\n","# Make predictions\n","predictions = model.predict(X)\n","print(predictions)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ol4DqZ8CNTfd","executionInfo":{"status":"ok","timestamp":1721983489024,"user_tz":-480,"elapsed":4954,"user":{"displayName":"Yen-Ting “Hiko” Lai","userId":"06414485255104484077"}},"outputId":"875ddc30-c147-4001-d0e1-fc0c6aa001df"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","1/1 [==============================] - 3s 3s/step - loss: 0.6950 - accuracy: 0.5000\n","Epoch 2/10\n","1/1 [==============================] - 0s 14ms/step - loss: 0.6916 - accuracy: 0.5000\n","Epoch 3/10\n","1/1 [==============================] - 0s 15ms/step - loss: 0.6883 - accuracy: 0.5000\n","Epoch 4/10\n","1/1 [==============================] - 0s 16ms/step - loss: 0.6850 - accuracy: 0.5000\n","Epoch 5/10\n","1/1 [==============================] - 0s 14ms/step - loss: 0.6817 - accuracy: 0.7500\n","Epoch 6/10\n","1/1 [==============================] - 0s 18ms/step - loss: 0.6783 - accuracy: 0.7500\n","Epoch 7/10\n","1/1 [==============================] - 0s 14ms/step - loss: 0.6748 - accuracy: 0.7500\n","Epoch 8/10\n","1/1 [==============================] - 0s 15ms/step - loss: 0.6713 - accuracy: 0.7500\n","Epoch 9/10\n","1/1 [==============================] - 0s 15ms/step - loss: 0.6675 - accuracy: 0.7500\n","Epoch 10/10\n","1/1 [==============================] - 0s 15ms/step - loss: 0.6636 - accuracy: 0.7500\n","Test Accuracy: 0.7500\n","1/1 [==============================] - 1s 541ms/step\n","[[0.54214   ]\n"," [0.5448219 ]\n"," [0.5214551 ]\n"," [0.53578043]]\n"]}]},{"cell_type":"markdown","source":["# Explanation:\n","\n"],"metadata":{"id":"Zagp4jo4N7BG"}},{"cell_type":"markdown","source":["* Tokenization: We use the \"Tokenizer\" class from Keras to convert the sentences into sequences of integers.\n","* Padding: We pad the sequences to ensure they are all the same length using the pad_sequences function.\n","* Model Definition: We define a simple LSTM model with an embedding layer, an LSTM layer, and a dense output layer with a sigmoid activation function.\n","* Model Compilation: We compile the model using the Adam optimizer and binary cross-entropy loss.\n","* Model Training: We train the model on the sample data for 10 epochs.\n","* Model Evaluation: We evaluate the model on the same data and print the accuracy.\n","* Predictions: We make predictions on the sample data and print the results."],"metadata":{"id":"I2qqgfX7PBvZ"}},{"cell_type":"markdown","source":["# Advanced NLP Tasks\n","Once you're comfortable with the basics, you can explore more advanced NLP tasks and models:"],"metadata":{"id":"JZ9VK6svOR_r"}},{"cell_type":"markdown","source":["* Named Entity Recognition (NER): Identifying entities like names, dates, and locations in text.\n","* Sentiment Analysis: Determining the sentiment (positive, negative, neutral) of a piece of text.\n","* Machine Translation: Translating text from one language to another.\n","* Text Summarization: Generating a summary of a given text.\n","* Question Answering: Building models that can answer questions based on a given context."],"metadata":{"id":"rFslAtz1O5Ba"}},{"cell_type":"markdown","source":["## Pre-trained Models and Libraries\n","There are several pre-trained models and libraries that can help you with advanced NLP tasks:"],"metadata":{"id":"RnhyVRQSPTuQ"}},{"cell_type":"markdown","source":["* spaCy: A popular NLP library with pre-trained models for various tasks.\n","* Hugging Face Transformers: A library with state-of-the-art pre-trained models like BERT, GPT-3, and more.\n","\n","Example: Using Hugging Face Transformers for Sentiment Analysis"],"metadata":{"id":"_fxVw3z5PY-C"}},{"cell_type":"code","source":["from transformers import pipeline\n","\n","# Load a pre-trained sentiment analysis pipeline\n","classifier = pipeline('sentiment-analysis')\n","\n","# Analyze sentiment of a sentence\n","result = classifier(\"I love natural language processing!\")\n","print(result)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":321,"referenced_widgets":["fe8ed05951f84f2792f26b2580c649e8","0ec29d7c95ad4d6f8b1e662325f4c86e","9ff0664d5bf64970b1fa8b0ee7a96a71","e954ea5d3d904d10a45dac4a3c8d3135","baf1c34863a94e5cafba3cc3dbff8fe6","ff1378e9516343e6853b4ed793aabf75","1c2c65b8b0724419b287bd6e0d3bee63","028d97a3e2434087a8e444def6356e90","7d3b1582f0dc46c1a76c71694389d837","e3a961fa6d8f4a41b76817f5a4187003","22e5df57ae1042a9808450afe895bb12","93d0fa07573d4f20829ce4e085b804ae","d08c3587f1824e949ee6f95ec2164513","18c6798927764af28b7a4b29ad0e5f16","f9f49aa54a8c49248d5d0f797a05c468","fbff010f602a42748a05b1b1d60c8fb3","57ae61048689429387628ad12ded1031","5066b3babcf54950ac8f6384f2ac4713","27cbf2d2e0f648698a6dfaa621c97a53","eac1f5994ccd440891e6dc2c2c2fc30c","9470da078c1848d294bb6eab9f741147","09242597b0974c63954fcdc76d8d6fa1","12cee0d391bf410ca6a1766e7a17ed3f","1346a66c59a24866a44fd8129467042d","67b11d23a61a42099b72f1074d8c461a","c91378932c6b4a9283cdeeeed90e12e6","4082d59c5cd34075bb760939ea8d5361","7e36eb67f9f54ee8b9fde5f7b780b5b7","e284f00702fb4ab3b574c29a57c13591","7691f35c1d4944d28a56c8f338de9103","c89bcba1de764d11a487070ebc06549f","522585be5d7d4e07b306cb6b0a787182","7262e28d92d64a35830a5da4a30b9c50","cf14fbdf087747c2b6f407360db8389e","99d9e8c59aa649ff8eb4c2afcf43fd95","d999409942c74faf8ce99537b8f5e8ed","1efe04c7ecde4a8faaf113f7aaac39fb","19dfef1e35ce4243b5932ae5102c91d3","d5f031fecc294319a90ee8db6243d7e7","5d47b721eee14fccada11e98438171df","048efe644e124dd6b83609c90cc8ecc5","1c41f870a4ae4ea5a99dc9d40ca56dd8","78a973a118c645eb8d4817b12f7fa4e2","49e2a781ea2640ec896c64ecb5ca8775"]},"id":"mdJ7U15BPkTi","executionInfo":{"status":"ok","timestamp":1721984017132,"user_tz":-480,"elapsed":25164,"user":{"displayName":"Yen-Ting “Hiko” Lai","userId":"06414485255104484077"}},"outputId":"3c211322-c279-498c-fadc-6db49cf59416"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stderr","text":["No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n","Using a pipeline without specifying a model name and revision in production is not recommended.\n","/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fe8ed05951f84f2792f26b2580c649e8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"93d0fa07573d4f20829ce4e085b804ae"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"12cee0d391bf410ca6a1766e7a17ed3f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf14fbdf087747c2b6f407360db8389e"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["[{'label': 'POSITIVE', 'score': 0.9998558759689331}]\n"]}]},{"cell_type":"markdown","source":["# Step-by-Step Example"],"metadata":{"id":"5-TVHMfvRsoW"}},{"cell_type":"markdown","source":["### 1. Data Loading and Preprocessing\n","First, let's load the IMDb dataset and preprocess the text data."],"metadata":{"id":"T4RcSYrPRyZt"}},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.datasets import imdb\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# Load the IMDb dataset\n","num_words = 10000  # Only consider the top 10,000 words\n","max_length = 200   # Maximum length of sequences\n","\n","(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=num_words)\n","\n","# Pad sequences to ensure they are all the same length\n","X_train = pad_sequences(X_train, maxlen=max_length, padding='post')\n","X_test = pad_sequences(X_test, maxlen=max_length, padding='post')\n","\n","print(f\"Training data shape: {X_train.shape}\")\n","print(f\"Test data shape: {X_test.shape}\")\n","print(f\"Training labels shape: {y_train.shape}\")\n","print(f\"Test labels shape: {y_test.shape}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YlgcgKRRRzbH","executionInfo":{"status":"ok","timestamp":1721984824684,"user_tz":-480,"elapsed":9561,"user":{"displayName":"Yen-Ting “Hiko” Lai","userId":"06414485255104484077"}},"outputId":"29fcc258-d6eb-418f-fe6a-bbaba08d1150"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Training data shape: (25000, 200)\n","Test data shape: (25000, 200)\n","Training labels shape: (25000,)\n","Test labels shape: (25000,)\n"]}]},{"cell_type":"markdown","source":["### 2. Building the LSTM Model\n","Next, we'll define and compile the LSTM model."],"metadata":{"id":"UanhXOiAR7s9"}},{"cell_type":"code","source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n","\n","# Define the LSTM model\n","model = Sequential()\n","model.add(Embedding(input_dim=num_words, output_dim=128, input_length=max_length))\n","model.add(LSTM(64, return_sequences=True))\n","model.add(Dropout(0.5))\n","model.add(LSTM(64))\n","model.add(Dropout(0.5))\n","model.add(Dense(1, activation='sigmoid'))\n","\n","# Compile the model\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","\n","# Print the model summary\n","model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jv5IkzpdR-2M","executionInfo":{"status":"ok","timestamp":1721984849245,"user_tz":-480,"elapsed":898,"user":{"displayName":"Yen-Ting “Hiko” Lai","userId":"06414485255104484077"}},"outputId":"49f05b08-c16f-429e-ed56-60ab5848da22"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding_1 (Embedding)     (None, 200, 128)          1280000   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 200, 64)           49408     \n","                                                                 \n"," dropout (Dropout)           (None, 200, 64)           0         \n","                                                                 \n"," lstm_2 (LSTM)               (None, 64)                33024     \n","                                                                 \n"," dropout_1 (Dropout)         (None, 64)                0         \n","                                                                 \n"," dense_1 (Dense)             (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 1362497 (5.20 MB)\n","Trainable params: 1362497 (5.20 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["### 3. Training the Model\n","Now, we'll train the model on the training data."],"metadata":{"id":"ytL-XXT4SBML"}},{"cell_type":"code","source":["# Train the model\n","history = model.fit(X_train, y_train, epochs=5, batch_size=64, validation_split=0.2, verbose=1)\n","\n","# Plot training and validation loss\n","plt.figure(figsize=(10, 5))\n","plt.plot(history.history['loss'], label='Training Loss')\n","plt.plot(history.history['val_loss'], label='Validation Loss')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.title('Training and Validation Loss Over Time')\n","plt.legend()\n","plt.show()\n","\n","# Plot training and validation accuracy\n","plt.figure(figsize=(10, 5))\n","plt.plot(history.history['accuracy'], label='Training Accuracy')\n","plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy')\n","plt.title('Training and Validation Accuracy Over Time')\n","plt.legend()\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":391},"id":"8349RP2gSEWg","executionInfo":{"status":"error","timestamp":1721984979138,"user_tz":-480,"elapsed":119381,"user":{"displayName":"Yen-Ting “Hiko” Lai","userId":"06414485255104484077"}},"outputId":"ec43de3d-42c5-46bc-ac14-039df40ee853"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","238/313 [=====================>........] - ETA: 34s - loss: 0.6749 - accuracy: 0.5658"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-d8b377099c04>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Plot training and validation loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1805\u001b[0m                         ):\n\u001b[1;32m   1806\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1807\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1808\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    866\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    869\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1321\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1322\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1487\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","source":["### 4. Evaluating the Model\n","We'll evaluate the model on the test data to see how well it performs."],"metadata":{"id":"7_dlXc_qSHME"}},{"cell_type":"code","source":["# Evaluate the model\n","test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n","print(f'Test Loss: {test_loss:.4f}')\n","print(f'Test Accuracy: {test_accuracy:.4f}')"],"metadata":{"id":"Qai4NePXSKBa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 5. Making Predictions\n","Finally, we'll make predictions on new data and interpret the results."],"metadata":{"id":"3Sx1d8pzSMWx"}},{"cell_type":"code","source":["# Make predictions\n","predictions = model.predict(X_test)\n","\n","# Convert predictions to binary labels\n","predicted_labels = (predictions > 0.5).astype(int)\n","\n","# Print some example predictions\n","for i in range(5):\n","    print(f\"Review: {X_test[i]}\")\n","    print(f\"Predicted Sentiment: {'Positive' if predicted_labels[i] == 1 else 'Negative'}\")\n","    print(f\"Actual Sentiment: {'Positive' if y_test[i] == 1 else 'Negative'}\")\n","    print()"],"metadata":{"id":"cwfqUphQSO-2"},"execution_count":null,"outputs":[]}]}