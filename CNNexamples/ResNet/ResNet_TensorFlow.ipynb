{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNP/nDEJWBpJtWT6PiYmBgb"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"prKKDWvr-gvx"},"outputs":[],"source":["import tensorflow as tf"]},{"cell_type":"markdown","source":["# 定義ResNet模型"],"metadata":{"id":"St8C5vKq-oeZ"}},{"cell_type":"code","source":["class BasicBlock(tf.keras.layers.Layer):\n","    def __init__(self, filters, stride=1):\n","        super(BasicBlock, self).__init__()\n","        self.conv1 = tf.keras.layers.Conv2D(filters, kernel_size=3, strides=stride, padding='same', use_bias=False)\n","        self.bn1 = tf.keras.layers.BatchNormalization()\n","        self.relu = tf.keras.layers.ReLU()\n","        self.conv2 = tf.keras.layers.Conv2D(filters, kernel_size=3, strides=1, padding='same', use_bias=False)\n","        self.bn2 = tf.keras.layers.BatchNormalization()\n","        self.downsample = None\n","        if stride != 1:\n","            self.downsample = tf.keras.Sequential([\n","                tf.keras.layers.Conv2D(filters, kernel_size=1, strides=stride, use_bias=False),\n","                tf.keras.layers.BatchNormalization()\n","            ])\n","\n","    def call(self, x, training=False):\n","        identity = x\n","        x = self.conv1(x)\n","        x = self.bn1(x, training=training)\n","        x = self.relu(x)\n","        x = self.conv2(x)\n","        x = self.bn2(x, training=training)\n","        if self.downsample is not None:\n","            identity = self.downsample(identity, training=training)\n","        x += identity\n","        x = self.relu(x)\n","        return x\n","\n","class ResNet(tf.keras.Model):\n","    def __init__(self, num_classes=10):\n","        super(ResNet, self).__init__()\n","        self.conv1 = tf.keras.layers.Conv2D(64, kernel_size=7, strides=2, padding='same', use_bias=False)\n","        self.bn1 = tf.keras.layers.BatchNormalization()\n","        self.relu = tf.keras.layers.ReLU()\n","        self.maxpool = tf.keras.layers.MaxPooling2D(pool_size=3, strides=2, padding='same')\n","        self.layer1 = self._make_layer(64, 2)\n","        self.layer2 = self._make_layer(128, 2, stride=2)\n","        self.layer3 = self._make_layer(256, 2, stride=2)\n","        self.layer4 = self._make_layer(512, 2, stride=2)\n","        self.avgpool = tf.keras.layers.GlobalAveragePooling2D()\n","        self.fc = tf.keras.layers.Dense(num_classes, activation='softmax')\n","\n","    def _make_layer(self, filters, blocks, stride=1):\n","        layers = []\n","        layers.append(BasicBlock(filters, stride))\n","        for _ in range(1, blocks):\n","            layers.append(BasicBlock(filters))\n","        return tf.keras.Sequential(layers)\n","\n","    def call(self, x, training=False):\n","        x = self.conv1(x)\n","        x = self.bn1(x, training=training)\n","        x = self.relu(x)\n","        x = self.maxpool(x)\n","        x = self.layer1(x, training=training)\n","        x = self.layer2(x, training=training)\n","        x = self.layer3(x, training=training)\n","        x = self.layer4(x, training=training)\n","        x = self.avgpool(x)\n","        x = self.fc(x)\n","        return x"],"metadata":{"id":"JHq4ljbr-olO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 創建ResNet-18模型"],"metadata":{"id":"DJwksCoN_Dac"}},{"cell_type":"code","source":["model = ResNet(num_classes=10)"],"metadata":{"id":"X7-Cgv-y_DgB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 編譯模型"],"metadata":{"id":"KIq1AJX2_GS0"}},{"cell_type":"code","source":["model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"],"metadata":{"id":"14MwsTf-_Gb1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 加載MNIST數據"],"metadata":{"id":"HZj_ALUZ_JTI"}},{"cell_type":"code","source":["(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n","train_images = train_images.reshape((60000, 28, 28, 1)).astype('float32') / 255\n","test_images = test_images.reshape((10000, 28, 28, 1)).astype('float32') / 255"],"metadata":{"id":"5T5zcCrZ_JYP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 訓練模型"],"metadata":{"id":"PIqpt5Yt_L2V"}},{"cell_type":"code","source":["model.fit(train_images, train_labels, epochs=10, batch_size=64, validation_data=(test_images, test_labels))"],"metadata":{"id":"2SqGa8r3_L-4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 評估模型"],"metadata":{"id":"7VLRoZVu_OY_"}},{"cell_type":"code","source":["test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)\n","print(f'Accuracy: {test_acc * 100}%')"],"metadata":{"id":"hkkjzUZM_OjX"},"execution_count":null,"outputs":[]}]}