{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNNYqV8irR3bAAPxDDlil69"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"tcxcSOGBhNMp"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras import layers, models\n","import matplotlib.pyplot as plt\n","import numpy as np"]},{"cell_type":"markdown","source":["# 定義AlexNet模型"],"metadata":{"id":"NE6yPKaIhTUo"}},{"cell_type":"code","source":["def AlexNet(input_shape=(224, 224, 1), num_classes=10):\n","    model = models.Sequential()\n","    model.add(layers.Conv2D(64, (11, 11), strides=4, padding='same', activation='relu', input_shape=input_shape))\n","    model.add(layers.MaxPooling2D((3, 3), strides=2))\n","    model.add(layers.Conv2D(192, (5, 5), padding='same', activation='relu'))\n","    model.add(layers.MaxPooling2D((3, 3), strides=2))\n","    model.add(layers.Conv2D(384, (3, 3), padding='same', activation='relu'))\n","    model.add(layers.Conv2D(256, (3, 3), padding='same', activation='relu'))\n","    model.add(layers.Conv2D(256, (3, 3), padding='same', activation='relu'))\n","    model.add(layers.MaxPooling2D((3, 3), strides=2))\n","    model.add(layers.Flatten())\n","    model.add(layers.Dropout(0.5))\n","    model.add(layers.Dense(4096, activation='relu'))\n","    model.add(layers.Dropout(0.5))\n","    model.add(layers.Dense(4096, activation='relu'))\n","    model.add(layers.Dense(num_classes, activation='softmax'))\n","    return model"],"metadata":{"id":"avOrxdI3hTbY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 編譯和訓練模型"],"metadata":{"id":"PBY3wry4hYRr"}},{"cell_type":"code","source":["model = AlexNet()\n","model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"],"metadata":{"id":"BBhxoSw9hYZ9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 加載資料集"],"metadata":{"id":"olaXAM05hhf8"}},{"cell_type":"code","source":["(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()"],"metadata":{"id":"ax7jZRpkhhov"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 調整圖像大小並標準化"],"metadata":{"id":"GDkddeNShmGs"}},{"cell_type":"code","source":["train_images = np.expand_dims(train_images, axis=-1)\n","test_images = np.expand_dims(test_images, axis=-1)\n","train_images = tf.image.resize(train_images, [224, 224])\n","test_images = tf.image.resize(test_images, [224, 224])\n","train_images = (train_images - 0.5) / 0.5\n","test_images = (test_images - 0.5) / 0.5"],"metadata":{"id":"m3ImH0AHhmRN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 可視化一些訓練圖像"],"metadata":{"id":"Zwe3QBZQhqzN"}},{"cell_type":"code","source":["fig, axes = plt.subplots(1, 8, figsize=(12, 12))\n","for i in range(8):\n","    axes[i].imshow(train_images[i].numpy().reshape(224, 224), cmap='gray')\n","    axes[i].set_title(f'Label: {train_labels[i]}')\n","    axes[i].axis('off')\n","plt.show()"],"metadata":{"id":"eqokrRP-hq5p"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 訓練模型並記錄損失和準確率"],"metadata":{"id":"Gj__4kOFhvQX"}},{"cell_type":"code","source":["history = model.fit(train_images, train_labels, epochs=10, batch_size=64, validation_data=(test_images, test_labels))\n","\n","# 可視化損失和準確率\n","fig, ax1 = plt.subplots()\n","\n","color = 'tab:red'\n","ax1.set_xlabel('Epoch')\n","ax1.set_ylabel('Loss', color=color)\n","ax1.plot(history.history['loss'], marker='o', color=color, label='Training Loss')\n","ax1.plot(history.history['val_loss'], marker='o', linestyle='dashed', color=color, label='Validation Loss')\n","ax1.tick_params(axis='y', labelcolor=color)\n","ax1.legend(loc='upper left')\n","\n","ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n","color = 'tab:blue'\n","ax2.set_ylabel('Accuracy', color=color)  # we already handled the x-label with ax1\n","ax2.plot(history.history['accuracy'], marker='o', color=color, label='Training Accuracy')\n","ax2.plot(history.history['val_accuracy'], marker='o', linestyle='dashed', color=color, label='Validation Accuracy')\n","ax2.tick_params(axis='y', labelcolor=color)\n","ax2.legend(loc='upper right')\n","\n","fig.tight_layout()  # otherwise the right y-label is slightly clipped\n","plt.title('Training and Validation Loss and Accuracy')\n","plt.show()"],"metadata":{"id":"-NW0lPrihvW6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 評估模型"],"metadata":{"id":"PMGUZv2xh40k"}},{"cell_type":"code","source":["test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)\n","print(f'Test accuracy: {test_acc}')\n","\n","# 可視化一些預測結果\n","predictions = model.predict(test_images)\n","\n","fig = plt.figure(figsize=(10, 10))\n","for i in range(1, 26):\n","    ax = fig.add_subplot(5, 5, i)\n","    ax.imshow(test_images[i].numpy().reshape(224, 224), cmap='gray')\n","    pred_label = np.argmax(predictions[i])\n","    true_label = test_labels[i]\n","    ax.title.set_text(f'Pred: {pred_label}, True: {true_label}')\n","    ax.axis('off')\n","plt.show()"],"metadata":{"id":"n6h1oo8Hh499"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"e6_Nsijkjxi_"}},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras import layers, models\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","# 定義AlexNet模型\n","def AlexNet(input_shape=(224, 224, 1), num_classes=10):\n","    model = models.Sequential()\n","    model.add(layers.Conv2D(64, (11, 11), strides=4, padding='same', activation='relu', input_shape=input_shape))\n","    model.add(layers.MaxPooling2D((3, 3), strides=2))\n","    model.add(layers.Conv2D(192, (5, 5), padding='same', activation='relu'))\n","    model.add(layers.MaxPooling2D((3, 3), strides=2))\n","    model.add(layers.Conv2D(384, (3, 3), padding='same', activation='relu'))\n","    model.add(layers.Conv2D(256, (3, 3), padding='same', activation='relu'))\n","    model.add(layers.Conv2D(256, (3, 3), padding='same', activation='relu'))\n","    model.add(layers.MaxPooling2D((3, 3), strides=2))\n","    model.add(layers.Flatten())\n","    model.add(layers.Dropout(0.5))\n","    model.add(layers.Dense(4096, activation='relu'))\n","    model.add(layers.Dropout(0.5))\n","    model.add(layers.Dense(4096, activation='relu'))\n","    model.add(layers.Dense(num_classes, activation='softmax'))\n","    return model\n","\n","# 編譯和訓練模型\n","model = AlexNet()\n","model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","\n","# 加載資料集\n","(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n","\n","# 調整圖像大小並標準化\n","train_images = np.expand_dims(train_images, axis=-1)\n","test_images = np.expand_dims(test_images, axis=-1)\n","train_images = tf.image.resize(train_images, [224, 224])\n","test_images = tf.image.resize(test_images, [224, 224])\n","train_images = (train_images - 0.5) / 0.5\n","test_images = (test_images - 0.5) / 0.5\n","\n","# 可視化一些訓練圖像\n","fig, axes = plt.subplots(1, 8, figsize=(12, 12))\n","for i in range(8):\n","    axes[i].imshow(train_images[i].numpy().reshape(224, 224), cmap='gray')\n","    axes[i].set_title(f'Label: {train_labels[i]}')\n","    axes[i].axis('off')\n","plt.show()\n","\n","# 訓練模型並記錄損失和準確率\n","history = model.fit(train_images, train_labels, epochs=10, batch_size=64, validation_data=(test_images, test_labels))\n","\n","# 可視化損失和準確率\n","fig, ax1 = plt.subplots()\n","\n","color = 'tab:red'\n","ax1.set_xlabel('Epoch')\n","ax1.set_ylabel('Loss', color=color)\n","ax1.plot(history.history['loss'], marker='o', color=color, label='Training Loss')\n","ax1.plot(history.history['val_loss'], marker='o', linestyle='dashed', color=color, label='Validation Loss')\n","ax1.tick_params(axis='y', labelcolor=color)\n","ax1.legend(loc='upper left')\n","\n","ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n","color = 'tab:blue'\n","ax2.set_ylabel('Accuracy', color=color)  # we already handled the x-label with ax1\n","ax2.plot(history.history['accuracy'], marker='o', color=color, label='Training Accuracy')\n","ax2.plot(history.history['val_accuracy'], marker='o', linestyle='dashed', color=color, label='Validation Accuracy')\n","ax2.tick_params(axis='y', labelcolor=color)\n","ax2.legend(loc='upper right')\n","\n","fig.tight_layout()  # otherwise the right y-label is slightly clipped\n","plt.title('Training and Validation Loss and Accuracy')\n","plt.show()\n","\n","# 評估模型\n","test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)\n","print(f'Test accuracy: {test_acc}')\n","\n","# 可視化一些預測結果\n","predictions = model.predict(test_images)\n","\n","fig = plt.figure(figsize=(10, 10))\n","for i in range(1, 26):\n","    ax = fig.add_subplot(5, 5, i)\n","    ax.imshow(test_images[i].numpy().reshape(224, 224), cmap='gray')\n","    pred_label = np.argmax(predictions[i])\n","    true_label = test_labels[i]\n","    ax.title.set_text(f'Pred: {pred_label}, True: {true_label}')\n","    ax.axis('off')\n","plt.show()"],"metadata":{"id":"1T3x8qf-jxs3"},"execution_count":null,"outputs":[]}]}